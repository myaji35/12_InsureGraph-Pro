"""
PDF Download, Text Extraction, and Entity Extraction Worker

71ê°œì˜ ì™„ë£Œëœ ë¬¸ì„œì—ì„œ PDFë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³ , í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œ í›„,
Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ 10ê°€ì§€ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""
import sys
import os
import asyncio
import uuid
from typing import List, Dict, Optional
from datetime import datetime
from pathlib import Path

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import requests
import pdfplumber
from loguru import logger
from anthropic import Anthropic
from sqlalchemy import text as sql_text

from app.core.database import AsyncSessionLocal
from app.core.config import settings

# PDF ì €ì¥ ê²½ë¡œ
PDF_DIR = Path(__file__).parent / "data" / "pdfs"
PDF_DIR.mkdir(parents=True, exist_ok=True)


class PDFEntityExtractor:
    """PDF ë‹¤ìš´ë¡œë“œ, í…ìŠ¤íŠ¸ ì¶”ì¶œ, ì—”í‹°í‹° ì¶”ì¶œì„ ìˆ˜í–‰í•˜ëŠ” ì›Œì»¤"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.anthropic_client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)

    async def run(self, limit: Optional[int] = None):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        logger.info("=" * 80)
        logger.info("ğŸ“š PDF Entity Extractor Worker Started")
        logger.info("=" * 80)

        # 1. ì™„ë£Œëœ ë¬¸ì„œ ì¡°íšŒ
        async with AsyncSessionLocal() as db:
            query_str = """
                SELECT id, title, insurer, category, product_type, pdf_url
                FROM crawler_documents
                WHERE status = 'completed'
                ORDER BY created_at DESC
            """
            if limit:
                query_str += f" LIMIT {limit}"

            result = await db.execute(sql_text(query_str))
            documents = result.fetchall()

        logger.info(f"ğŸ“„ Found {len(documents)} completed documents")

        # 2. ê° ë¬¸ì„œ ì²˜ë¦¬
        total_entities = 0
        total_relationships = 0
        processed_count = 0
        failed_count = 0

        for doc in documents:
            doc_id, title, insurer, category, product_type, pdf_url = doc
            doc_id = str(doc_id)

            try:
                logger.info(f"\n{'=' * 80}")
                logger.info(f"ğŸ“„ Processing: {title[:50]}...")
                logger.info(f"   ë³´í—˜ì‚¬: {insurer}, ì¹´í…Œê³ ë¦¬: {category}")

                # Step 1: PDF ë‹¤ìš´ë¡œë“œ
                pdf_path = await self.download_pdf(doc_id, pdf_url, title)
                if not pdf_path:
                    logger.error(f"Failed to download PDF for {doc_id}")
                    failed_count += 1
                    continue

                # Step 2: í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = await self.extract_text_from_pdf(pdf_path)
                if not text or len(text) < 500:
                    logger.warning(f"Insufficient text extracted: {len(text)} chars")
                    failed_count += 1
                    continue

                logger.info(f"âœ… Extracted {len(text):,} characters")

                # Step 3: Claude APIë¡œ ì—”í‹°í‹° ì¶”ì¶œ
                entities, relationships = await self.extract_entities_with_claude(
                    text, doc_id, title, insurer, product_type
                )

                # Step 4: ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                saved_entities, saved_relationships = await self.save_entities(
                    doc_id, entities, relationships
                )

                total_entities += saved_entities
                total_relationships += saved_relationships
                processed_count += 1

                logger.info(f"âœ… Saved {saved_entities} entities, {saved_relationships} relationships")

            except Exception as e:
                logger.error(f"âŒ Error processing {doc_id}: {e}", exc_info=True)
                failed_count += 1

        # 3. ìµœì¢… í†µê³„
        logger.info(f"\n{'=' * 80}")
        logger.info(f"ğŸ“Š Final Statistics:")
        logger.info(f"   Total Documents: {len(documents)}")
        logger.info(f"   Processed: {processed_count}")
        logger.info(f"   Failed: {failed_count}")
        logger.info(f"   Total Entities: {total_entities}")
        logger.info(f"   Total Relationships: {total_relationships}")
        logger.info(f"={'=' * 80}")

    async def download_pdf(self, doc_id: str, pdf_url: str, title: str) -> Optional[Path]:
        """PDF ë‹¤ìš´ë¡œë“œ"""
        try:
            # íŒŒì¼ëª… ìƒì„±
            safe_filename = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in title[:50])
            pdf_filename = f"{doc_id}_{safe_filename}.pdf"
            pdf_path = PDF_DIR / pdf_filename

            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ
            if pdf_path.exists():
                logger.info(f"   PDF already exists: {pdf_filename}")
                return pdf_path

            # PDF ë‹¤ìš´ë¡œë“œ
            logger.info(f"   Downloading PDF from {pdf_url[:60]}...")
            response = requests.get(pdf_url, timeout=30)
            response.raise_for_status()

            # íŒŒì¼ ì €ì¥
            with open(pdf_path, 'wb') as f:
                f.write(response.content)

            logger.info(f"   âœ… Downloaded: {len(response.content):,} bytes")
            return pdf_path

        except Exception as e:
            logger.error(f"   âŒ Download failed: {e}")
            return None

    async def extract_text_from_pdf(self, pdf_path: Path) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            text_parts = []

            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, 1):
                    page_text = page.extract_text()
                    if page_text:
                        text_parts.append(page_text)

            full_text = "\n\n".join(text_parts)
            return full_text

        except Exception as e:
            logger.error(f"   âŒ Text extraction failed: {e}")
            return ""

    async def extract_entities_with_claude(
        self,
        text: str,
        doc_id: str,
        title: str,
        insurer: str,
        product_type: str
    ) -> tuple[List[Dict], List[Dict]]:
        """Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—”í‹°í‹° ì¶”ì¶œ"""
        try:
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (Claude API í† í° ì œí•œ)
            max_chars = 50000
            if len(text) > max_chars:
                text = text[:max_chars] + "\n\n[í…ìŠ¤íŠ¸ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤...]"

            prompt = f"""ë‹¤ìŒì€ {insurer}ì˜ {product_type} ë³´í—˜ì•½ê´€ ë¬¸ì„œì…ë‹ˆë‹¤.

ë¬¸ì„œ ì œëª©: {title}

ë³´í—˜ì•½ê´€ ë‚´ìš©:
{text}

ìœ„ ë³´í—˜ì•½ê´€ì—ì„œ ë‹¤ìŒ 10ê°€ì§€ íƒ€ì…ì˜ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. coverage_item (ë³´ì¥í•­ëª©): ë³´í—˜ì—ì„œ ë³´ì¥í•˜ëŠ” í•­ëª©
2. benefit_amount (ë³´í—˜ê¸ˆì•¡): ì§€ê¸‰ë˜ëŠ” ë³´í—˜ê¸ˆ ê¸ˆì•¡
3. payment_condition (ì§€ê¸‰ì¡°ê±´): ë³´í—˜ê¸ˆ ì§€ê¸‰ ì¡°ê±´
4. exclusion (ë©´ì±…ì‚¬í•­): ë³´ì¥í•˜ì§€ ì•ŠëŠ” ì‚¬í•­
5. deductible (ìê¸°ë¶€ë‹´ê¸ˆ): ë³¸ì¸ì´ ë¶€ë‹´í•´ì•¼ í•˜ëŠ” ê¸ˆì•¡
6. rider (íŠ¹ì•½): ì¶”ê°€ íŠ¹ì•½
7. eligibility (ê°€ì…ì¡°ê±´): ê°€ì… ê°€ëŠ¥í•œ ì¡°ê±´
8. article (ì•½ê´€ì¡°í•­): ì•½ê´€ ì¡°í•­ ë²ˆí˜¸
9. term (ë³´í—˜ìš©ì–´): ë³´í—˜ ê´€ë ¨ ìš©ì–´
10. period (ê¸°ê°„): ë³´í—˜ ê´€ë ¨ ê¸°ê°„

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "entities": [
    {{
      "label": "ì—”í‹°í‹° ì´ë¦„",
      "type": "ì—”í‹°í‹° íƒ€ì…",
      "description": "ì—”í‹°í‹° ì„¤ëª… (1-2ë¬¸ì¥)",
      "source_text": "ì—”í‹°í‹°ê°€ ë°œê²¬ëœ ì›ë¬¸ (ìµœëŒ€ 200ì)"
    }}
  ]
}}

ìµœëŒ€ 50ê°œì˜ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ë˜, ê°€ì¥ ì¤‘ìš”í•œ ê²ƒë“¤ë§Œ ì„ íƒí•´ì£¼ì„¸ìš”.
"""

            logger.info(f"   ğŸ¤– Calling Claude API...")

            message = self.anthropic_client.messages.create(
                model="claude-sonnet-4-5",
                max_tokens=4000,
                temperature=0.1,
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )

            # ì‘ë‹µ íŒŒì‹±
            response_text = message.content[0].text
            logger.debug(f"Claude response: {response_text[:200]}...")

            # JSON íŒŒì‹±
            import json
            # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` ì œê±°)
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            json_text = response_text[json_start:json_end]

            result = json.loads(json_text)
            raw_entities = result.get('entities', [])

            # ì—”í‹°í‹° í¬ë§· ë³€í™˜
            entities = []
            for ent in raw_entities:
                entity = {
                    "entity_id": str(uuid.uuid4()),
                    "label": ent.get("label", "").strip()[:200],
                    "type": ent.get("type", "term"),
                    "description": ent.get("description", "").strip()[:500],
                    "source_text": ent.get("source_text", "").strip()[:200],
                    "document_id": doc_id,
                    "insurer": insurer,
                    "product_type": product_type,
                    "created_at": datetime.utcnow()
                }
                entities.append(entity)

            logger.info(f"   âœ… Extracted {len(entities)} entities from Claude API")

            # ê°„ë‹¨í•œ ê´€ê³„ ìƒì„± (ê°™ì€ ë¬¸ì„œ ë‚´ ì—”í‹°í‹°ë¼ë¦¬ ì—°ê²°)
            relationships = []
            coverage_items = [e for e in entities if e['type'] == 'coverage_item']
            benefit_amounts = [e for e in entities if e['type'] == 'benefit_amount']

            # coverage_item <-> benefit_amount ê´€ê³„
            for cov in coverage_items[:5]:  # ìµœëŒ€ 5ê°œë§Œ
                for amt in benefit_amounts[:3]:  # ê°ê° 3ê°œì”©ë§Œ
                    relationships.append({
                        "source_entity_id": cov["entity_id"],
                        "target_entity_id": amt["entity_id"],
                        "type": "has_amount",
                        "description": f"{cov['label']}ì˜ ë³´í—˜ê¸ˆì•¡ì€ {amt['label']}ì…ë‹ˆë‹¤",
                        "created_at": datetime.utcnow()
                    })

            return entities, relationships

        except Exception as e:
            logger.error(f"   âŒ Claude API extraction failed: {repr(e)}")
            return [], []

    async def save_entities(
        self,
        doc_id: str,
        entities: List[Dict],
        relationships: List[Dict]
    ) -> tuple[int, int]:
        """ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            async with AsyncSessionLocal() as db:
                # ê¸°ì¡´ ì—”í‹°í‹° ì‚­ì œ
                await db.execute(
                    sql_text("DELETE FROM knowledge_entities WHERE document_id = :doc_id"),
                    {"doc_id": doc_id}
                )

                # ì—”í‹°í‹° ì €ì¥
                entity_count = 0
                for entity in entities:
                    await db.execute(sql_text("""
                        INSERT INTO knowledge_entities (
                            entity_id, label, type, description, source_text,
                            document_id, insurer, product_type, created_at
                        ) VALUES (
                            :entity_id, :label, :type, :description, :source_text,
                            :document_id, :insurer, :product_type, :created_at
                        )
                    """), entity)
                    entity_count += 1

                # ê´€ê³„ ì €ì¥
                relationship_count = 0
                for rel in relationships:
                    try:
                        await db.execute(sql_text("""
                            INSERT INTO knowledge_relationships (
                                source_entity_id, target_entity_id, type, description, created_at
                            ) VALUES (
                                :source_entity_id, :target_entity_id, :type, :description, :created_at
                            )
                        """), rel)
                        relationship_count += 1
                    except Exception:
                        pass  # ì¤‘ë³µ ê´€ê³„ëŠ” ë¬´ì‹œ

                await db.commit()

                return entity_count, relationship_count

        except Exception as e:
            logger.error(f"   âŒ Save failed: {e}", exc_info=True)
            return 0, 0


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys

    # ëª…ë ¹ì¤„ ì¸ìë¡œ limit ë°›ê¸°
    limit = int(sys.argv[1]) if len(sys.argv) > 1 else 5  # ê¸°ë³¸ 5ê°œ

    extractor = PDFEntityExtractor()
    await extractor.run(limit=limit)


if __name__ == "__main__":
    asyncio.run(main())
