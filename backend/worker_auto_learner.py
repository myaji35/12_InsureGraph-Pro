"""
ìë™ ë¬¸ì„œ í•™ìŠµ ì›Œì»¤

ìƒˆë¡œ í¬ë¡¤ë§ëœ ë¬¸ì„œ(pending ìƒíƒœ)ë¥¼ ê°ì§€í•˜ì—¬ ìë™ìœ¼ë¡œ ê·¸ë˜í”„ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.
- 5ê°œì”© ë°°ì¹˜ë¡œ ì²˜ë¦¬
- ì²˜ë¦¬ ì¤‘ì¸ ë¬¸ì„œê°€ ì—†ì„ ë•Œë§Œ ìƒˆ ë°°ì¹˜ ì‹œì‘
- 30ì´ˆë§ˆë‹¤ ì²´í¬
"""
import asyncio
import signal
import sys
from datetime import datetime
from loguru import logger

from app.services.parallel_document_processor import ParallelDocumentProcessor
from app.core.database import AsyncSessionLocal
from sqlalchemy import text


class AutoLearningWorker:
    """ìë™ í•™ìŠµ ì›Œì»¤"""

    def __init__(
        self,
        max_concurrent: int = 5,
        batch_size: int = 10,
        check_interval: int = 30
    ):
        """
        Args:
            max_concurrent: ë™ì‹œ ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜
            batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ë°°ì¹˜ í¬ê¸°
            check_interval: ì²´í¬ ê°„ê²© (ì´ˆ)
        """
        self.max_concurrent = max_concurrent
        self.batch_size = batch_size
        self.check_interval = check_interval
        self.processor = ParallelDocumentProcessor(max_concurrent=max_concurrent)
        self.is_running = True
        self.total_processed = 0

        # Graceful shutdown ì„¤ì •
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def _signal_handler(self, signum, frame):
        """ì¢…ë£Œ ì‹œê·¸ë„ ì²˜ë¦¬"""
        logger.info(f"Received signal {signum}. Shutting down gracefully...")
        self.is_running = False

    async def get_processing_count(self) -> int:
        """í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë¬¸ì„œ ìˆ˜ ì¡°íšŒ"""
        async with AsyncSessionLocal() as db:
            query = text("""
                SELECT COUNT(*) as count
                FROM crawler_documents
                WHERE status = 'processing'
            """)
            result = await db.execute(query)
            row = result.fetchone()
            return row[0] if row else 0

    async def get_pending_count(self) -> int:
        """ëŒ€ê¸° ì¤‘ì¸ ë¬¸ì„œ ìˆ˜ ì¡°íšŒ"""
        async with AsyncSessionLocal() as db:
            query = text("""
                SELECT COUNT(*) as count
                FROM crawler_documents
                WHERE status = 'pending'
            """)
            result = await db.execute(query)
            row = result.fetchone()
            return row[0] if row else 0

    async def run(self):
        """ì›Œì»¤ ì‹¤í–‰"""
        logger.info("=" * 80)
        logger.info("ğŸš€ Auto Learning Worker Started")
        logger.info(f"  - Max Concurrent: {self.max_concurrent}")
        logger.info(f"  - Batch Size: {self.batch_size}")
        logger.info(f"  - Check Interval: {self.check_interval}s")
        logger.info("=" * 80)

        while self.is_running:
            try:
                # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë¬¸ì„œ ìˆ˜ í™•ì¸
                processing_count = await self.get_processing_count()
                pending_count = await self.get_pending_count()

                logger.info(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] "
                          f"Processing: {processing_count}, Pending: {pending_count}, "
                          f"Total Processed: {self.total_processed}")

                # ì²˜ë¦¬ ì¤‘ì¸ ë¬¸ì„œê°€ ì—†ê³ , ëŒ€ê¸° ì¤‘ì¸ ë¬¸ì„œê°€ ìˆìœ¼ë©´ ìƒˆ ë°°ì¹˜ ì‹œì‘
                if processing_count == 0 and pending_count > 0:
                    logger.info(f"ğŸ¯ Starting new batch: {self.batch_size} documents")

                    result = await self.processor.process_pending_documents(
                        limit=self.batch_size
                    )

                    self.total_processed += result["success"]

                    logger.info(f"âœ… Batch completed: {result['success']} success, "
                              f"{result['failed']} failed out of {result['total']} total")
                    logger.info(f"ğŸ“Š Total processed so far: {self.total_processed}")

                elif processing_count > 0:
                    logger.info(f"â³ Waiting for current batch to complete ({processing_count} documents processing)...")

                else:
                    logger.info("ğŸ’¤ No pending documents. Waiting for new documents...")

                # ë‹¤ìŒ ì²´í¬ê¹Œì§€ ëŒ€ê¸°
                await asyncio.sleep(self.check_interval)

            except Exception as e:
                logger.error(f"âŒ Worker error: {e}", exc_info=True)
                await asyncio.sleep(self.check_interval)

        logger.info("=" * 80)
        logger.info(f"ğŸ›‘ Auto Learning Worker Stopped. Total processed: {self.total_processed}")
        logger.info("=" * 80)


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì íŒŒì‹±
    max_concurrent = int(sys.argv[1]) if len(sys.argv) > 1 else 5
    batch_size = int(sys.argv[2]) if len(sys.argv) > 2 else 10
    check_interval = int(sys.argv[3]) if len(sys.argv) > 3 else 30

    worker = AutoLearningWorker(
        max_concurrent=max_concurrent,
        batch_size=batch_size,
        check_interval=check_interval
    )

    await worker.run()


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆ:
    # python worker_auto_learner.py 5 10 30
    # (5ê°œ ë™ì‹œ, 10ê°œ ë°°ì¹˜, 30ì´ˆ ê°„ê²©)
    asyncio.run(main())
