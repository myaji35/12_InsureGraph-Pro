"""
Insurance Crawlers Test Script

ë³´í—˜ì‚¬ í¬ë¡¤ëŸ¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ë° ë°ëª¨
"""
import asyncio

# í¬ë¡¤ëŸ¬ ì‹œìŠ¤í…œ import
from app.services.crawlers import (
    get_crawler,
    get_all_crawlers,
    get_available_insurers,
    is_insurer_supported,
)
from app.services.crawlers.config_loader import load_insurer_config, load_all_insurer_configs


async def test_available_insurers():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë³´í—˜ì‚¬ í™•ì¸"""
    print("\n" + "="*60)
    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë³´í—˜ì‚¬ ëª©ë¡")
    print("="*60)

    insurers = get_available_insurers()

    if not insurers:
        print("âš ï¸  ë“±ë¡ëœ ë³´í—˜ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for insurer_code in insurers:
        supported = "âœ…" if is_insurer_supported(insurer_code) else "âŒ"
        print(f"{supported} {insurer_code}")

    print(f"\nì´ {len(insurers)}ê°œ ë³´í—˜ì‚¬ ì§€ì›")


async def test_config_loading():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("âš™ï¸  ì„¤ì • íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸")
    print("="*60)

    try:
        configs = load_all_insurer_configs()

        for insurer_code, config in configs.items():
            print(f"\n{config.insurer_name} ({insurer_code}):")
            print(f"  - Base URL: {config.base_url}")
            print(f"  - Crawl Method: {config.crawl_method.value}")
            print(f"  - Has Pagination: {config.has_pagination}")
            print(f"  - Request Delay: {config.request_delay}s")

        if not configs:
            print("âš ï¸  ë¡œë“œëœ ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")


async def test_crawler_creation():
    """í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("ğŸ­ í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸")
    print("="*60)

    insurers = get_available_insurers()

    for insurer_code in insurers:
        try:
            crawler = get_crawler(insurer_code)
            print(f"âœ… {crawler.config.insurer_name}: {type(crawler).__name__}")

        except Exception as e:
            print(f"âŒ {insurer_code}: {e}")


async def test_connection(insurer_code: str):
    """íŠ¹ì • ë³´í—˜ì‚¬ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print(f"ğŸ”— {insurer_code} ì—°ê²° í…ŒìŠ¤íŠ¸")
    print("="*60)

    try:
        crawler = get_crawler(insurer_code)

        print(f"ë³´í—˜ì‚¬: {crawler.config.insurer_name}")
        print(f"URL: {crawler.config.base_url}")
        print(f"í¬ë¡¤ë§ ë°©ë²•: {crawler.config.crawl_method.value}")

        print("\nì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        is_connected = await crawler.test_connection()

        if is_connected:
            print("âœ… ì—°ê²° ì„±ê³µ")
        else:
            print("âŒ ì—°ê²° ì‹¤íŒ¨ (ì›¹ì‚¬ì´íŠ¸ê°€ ë‹¤ìš´ë˜ì—ˆê±°ë‚˜ URLì´ ì˜ëª»ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

    except KeyError:
        print(f"âŒ '{insurer_code}' í¬ë¡¤ëŸ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")


async def demo_crawling_flow(insurer_code: str = "samsung_life"):
    """í¬ë¡¤ë§ í”Œë¡œìš° ë°ëª¨ (ì‹¤ì œ í¬ë¡¤ë§ ì—†ì´ êµ¬ì¡°ë§Œ ë³´ì—¬ì¤Œ)"""
    print("\n" + "="*60)
    print(f"ğŸ¬ {insurer_code} í¬ë¡¤ë§ í”Œë¡œìš° ë°ëª¨")
    print("="*60)

    try:
        crawler = get_crawler(insurer_code)

        print("\n1ï¸âƒ£ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”")
        print(f"   ë³´í—˜ì‚¬: {crawler.config.insurer_name}")
        print(f"   ë°©ë²•: {crawler.config.crawl_method.value}")

        print("\n2ï¸âƒ£ ìƒí’ˆ ëª©ë¡ ì¡°íšŒ (ì‹œë®¬ë ˆì´ì…˜)")
        print("   - ì•”ë³´í—˜: 5ê°œ ìƒí’ˆ")
        print("   - ì‹¤ì†ë³´í—˜: 3ê°œ ìƒí’ˆ")
        print("   - ì¢…ì‹ ë³´í—˜: 4ê°œ ìƒí’ˆ")

        print("\n3ï¸âƒ£ ì•½ê´€ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)")
        print("   - ìƒí’ˆëª…, ì½”ë“œ, ì¹´í…Œê³ ë¦¬")
        print("   - ë‹¤ìš´ë¡œë“œ URL, ë²„ì „, ì‹œí–‰ì¼")

        print("\n4ï¸âƒ£ ì•½ê´€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì‹œë®¬ë ˆì´ì…˜)")
        print("   - PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
        print("   - ë¡œì»¬ ì €ì¥ì†Œì— ì €ì¥")

        print("\n5ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (ì‹œë®¬ë ˆì´ì…˜)")
        print("   - policy_metadata í…Œì´ë¸”ì— ì €ì¥")
        print("   - ingestion_jobsì— ì‘ì—… ë“±ë¡")

        print("\nâœ… í¬ë¡¤ë§ í”Œë¡œìš° ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")


async def show_crawler_info(insurer_code: str):
    """íŠ¹ì • í¬ë¡¤ëŸ¬ ìƒì„¸ ì •ë³´"""
    print("\n" + "="*60)
    print(f"â„¹ï¸  {insurer_code} í¬ë¡¤ëŸ¬ ì •ë³´")
    print("="*60)

    try:
        crawler = get_crawler(insurer_code)
        config = crawler.config

        print(f"\nê¸°ë³¸ ì •ë³´:")
        print(f"  ì½”ë“œ: {config.insurer_code}")
        print(f"  ì´ë¦„: {config.insurer_name}")
        print(f"  URL: {config.base_url}")

        print(f"\ní¬ë¡¤ë§ ì„¤ì •:")
        print(f"  ë°©ë²•: {config.crawl_method.value}")
        print(f"  ì¸ì¦: {config.auth_method.value}")
        print(f"  í˜ì´ì§€ë„¤ì´ì…˜: {config.has_pagination}")
        print(f"  ìµœëŒ€ í˜ì´ì§€: {config.max_pages}")

        print(f"\nRate Limiting:")
        print(f"  ìš”ì²­ ê°„ê²©: {config.request_delay}ì´ˆ")
        print(f"  ìµœëŒ€ ì¬ì‹œë„: {config.max_retries}íšŒ")

        print(f"\nSelectors:")
        print(f"  ìƒí’ˆ ëª©ë¡: {config.product_list_selector}")
        print(f"  ìƒí’ˆëª…: {config.product_name_selector}")
        print(f"  ì¹´í…Œê³ ë¦¬: {config.product_category_selector}")
        print(f"  ë‹¤ìš´ë¡œë“œ: {config.download_link_selector}")

        if config.metadata:
            print(f"\nì¶”ê°€ ì •ë³´:")
            for key, value in config.metadata.items():
                if key != "notes":
                    print(f"  {key}: {value}")

    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ğŸ§ª Insurance Crawler System Test")
    print("="*60)

    # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ë³´í—˜ì‚¬ í™•ì¸
    await test_available_insurers()

    # 2. ì„¤ì • íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸
    await test_config_loading()

    # 3. í¬ë¡¤ëŸ¬ ìƒì„± í…ŒìŠ¤íŠ¸
    await test_crawler_creation()

    # 4. ì—°ê²° í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ì— ì ‘ì†)
    insurers = get_available_insurers()
    if insurers:
        await test_connection(insurers[0])

    # 5. í¬ë¡¤ë§ í”Œë¡œìš° ë°ëª¨
    await demo_crawling_flow()

    # 6. ìƒì„¸ ì •ë³´ ì¶œë ¥
    if insurers:
        await show_crawler_info(insurers[0])

    print("\n" + "="*60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("="*60)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(main())
