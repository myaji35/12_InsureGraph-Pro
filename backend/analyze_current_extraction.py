"""
í˜„ì¬ ì‹œìŠ¤í…œì˜ PDF ì¶”ì¶œ í’ˆì§ˆ ë¶„ì„

pdfplumberë¡œ ì¶”ì¶œëœ í˜„ì¬ ë°ì´í„°ì˜ í’ˆì§ˆì„ ë¶„ì„í•˜ì—¬
Upstage ë„ì…ì˜ í•„ìš”ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.

Usage:
    python3 analyze_current_extraction.py
"""
import time
import re
from pathlib import Path


# ============================================================================
# ìƒ˜í”Œ PDF íŒŒì¼ ì„ íƒ
# ============================================================================
PDF_DIR = Path(__file__).parent / "data" / "pdfs"
PDF_DIR_LLM = Path(__file__).parent / "data" / "pdfs_llm"


def get_sample_pdfs(limit=5):
    """ë¡œì»¬ì—ì„œ ìƒ˜í”Œ PDF íŒŒì¼ ê°€ì ¸ì˜¤ê¸°"""
    pdf_files = []

    if PDF_DIR.exists():
        pdf_files.extend(list(PDF_DIR.glob("*.pdf")))

    if PDF_DIR_LLM.exists():
        pdf_files.extend(list(PDF_DIR_LLM.glob("*.pdf")))

    samples = []
    for pdf_path in pdf_files[:limit]:
        filename = pdf_path.name

        # ë³´í—˜ì‚¬ ì¶”ì •
        insurer = "Unknown"
        if "ì• ë‹ˆì¹´" in filename:
            insurer = "ì‚¼ì„±í™”ì¬"
        elif "KB" in filename or "kb" in filename.lower():
            insurer = "KBì†í•´ë³´í—˜"
        elif "ì‚¼ì„±" in filename:
            insurer = "ì‚¼ì„±ìƒëª…"

        # ìƒí’ˆ ìœ í˜• ì¶”ì •
        product_type = "Unknown"
        if "ìë™ì°¨" in filename:
            product_type = "ìë™ì°¨ë³´í—˜"
        elif "ì—°ê¸ˆ" in filename:
            product_type = "ì—°ê¸ˆë³´í—˜"
        elif "ì¢…ì‹ " in filename:
            product_type = "ì¢…ì‹ ë³´í—˜"

        samples.append({
            'file_path': str(pdf_path),
            'filename': filename,
            'insurer': insurer,
            'product_type': product_type,
            'file_size': pdf_path.stat().st_size
        })

    return samples


# ============================================================================
# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ - pdfplumber (í˜„ì¬ ì‹œìŠ¤í…œ)
# ============================================================================
def extract_with_pdfplumber(file_path: str):
    """pdfplumberë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        import pdfplumber

        extracted_text = ""
        total_pages = 0

        with pdfplumber.open(file_path) as pdf:
            total_pages = len(pdf.pages)
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    extracted_text += text + "\n"

        return {
            'text': extracted_text,
            'total_pages': total_pages,
            'method': 'pdfplumber'
        }

    except Exception as e:
        print(f"   âŒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None


# ============================================================================
# í’ˆì§ˆ ë¶„ì„ í•¨ìˆ˜ë“¤
# ============================================================================
def calculate_text_quality(text: str):
    """í…ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
    if not text:
        return {
            'korean_ratio': 0.0,
            'structure_score': 0.0,
            'readability_score': 0.0,
            'overall_score': 0.0
        }

    # 1. í•œê¸€ ë¹„ìœ¨ (ë³´í—˜ì•½ê´€ì€ í•œê¸€ì´ ë§ì•„ì•¼ í•¨)
    korean_chars = sum(1 for c in text if ord('ê°€') <= ord(c) <= ord('í£'))
    korean_ratio = korean_chars / len(text) if text else 0

    # 2. êµ¬ì¡°í™” ì ìˆ˜ (ì œ1ì¡°, ì œ1ì¥ ë“±ì˜ íŒ¨í„´ ì¸ì‹)
    chapters = len(re.findall(r'ì œ\d+ì¥', text))
    articles = len(re.findall(r'ì œ\d+ì¡°', text))
    structure_score = min((chapters * 2 + articles) / 100, 1.0)

    # 3. ê°€ë…ì„± ì ìˆ˜
    lines = [line for line in text.split('\n') if line.strip()]
    avg_line_length = sum(len(line) for line in lines) / len(lines) if lines else 0

    special_chars = sum(1 for c in text if not c.isalnum() and not c.isspace())
    special_ratio = special_chars / len(text) if text else 0

    readability_score = 0.0
    readability_score += min(avg_line_length / 50, 0.5)
    readability_score += max(0.5 - special_ratio, 0)

    # 4. ì¢…í•© ì ìˆ˜
    overall = (
        korean_ratio * 0.4 +
        structure_score * 0.3 +
        readability_score * 0.3
    )

    return {
        'korean_ratio': round(korean_ratio, 3),
        'structure_score': round(structure_score, 3),
        'readability_score': round(readability_score, 3),
        'overall_score': round(overall, 3),
        'chapters': chapters,
        'articles': articles
    }


def calculate_uds_interpretation(text: str):
    """UDS (Understanding, Detail, Structure) í•´ì„ë ¥ ê³„ì‚°"""
    quality = calculate_text_quality(text)

    # Understanding (ì´í•´ë„): í…ìŠ¤íŠ¸ í’ˆì§ˆ ê¸°ë°˜
    understanding = quality['overall_score'] * 100

    # Detail (ìƒì„¸ë„): í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜
    text_length = len(text)
    detail = min(text_length / 50000, 1.0) * 100

    # Structure (êµ¬ì¡°í™”): ì¡°í•­ ìˆ˜ ê¸°ë°˜
    chapters = quality['chapters']
    articles = quality['articles']
    structure = min((chapters * 5 + articles * 2), 100)

    # Total
    total = (understanding * 0.3 + detail * 0.3 + structure * 0.4)

    return {
        'understanding': round(understanding, 1),
        'detail': round(detail, 1),
        'structure': round(structure, 1),
        'total': round(total, 1)
    }


def analyze_potential_issues(text: str):
    """ì ì¬ì  ë¬¸ì œì  ë¶„ì„"""
    issues = []

    # 1. í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì€ ê²½ìš°
    if len(text) < 1000:
        issues.append("âš ï¸  ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë§¤ìš° ì§§ìŠµë‹ˆë‹¤ (OCR í•„ìš” ê°€ëŠ¥ì„±)")

    # 2. í•œê¸€ ë¹„ìœ¨ì´ ë‚®ì€ ê²½ìš°
    korean_chars = sum(1 for c in text if ord('ê°€') <= ord(c) <= ord('í£'))
    korean_ratio = korean_chars / len(text) if text else 0
    if korean_ratio < 0.3:
        issues.append(f"âš ï¸  í•œê¸€ ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤ ({korean_ratio:.1%}) - OCR í’ˆì§ˆ ë¬¸ì œ ê°€ëŠ¥")

    # 3. ì¡°í•­ êµ¬ì¡°ê°€ ì—†ëŠ” ê²½ìš°
    articles = len(re.findall(r'ì œ\d+ì¡°', text))
    if articles < 5:
        issues.append(f"âš ï¸  ì¡°í•­ êµ¬ì¡° ì¸ì‹ ì‹¤íŒ¨ (ì œNì¡° íŒ¨í„´: {articles}ê°œë§Œ ë°œê²¬)")

    # 4. íŠ¹ìˆ˜ë¬¸ìê°€ ë„ˆë¬´ ë§ì€ ê²½ìš°
    special_chars = sum(1 for c in text if not c.isalnum() and not c.isspace())
    special_ratio = special_chars / len(text) if text else 0
    if special_ratio > 0.3:
        issues.append(f"âš ï¸  íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤ ({special_ratio:.1%}) - ë ˆì´ì•„ì›ƒ ê¹¨ì§ ê°€ëŠ¥")

    # 5. í‘œ ì¶”ì¶œ ë¶€ì¬
    table_indicators = ['â”Œ', 'â”', 'â””', 'â”˜', 'â”‚', 'â”€']
    has_table_chars = any(char in text for char in table_indicators)
    if not has_table_chars:
        # í‘œê°€ ìˆì„ ë²•í•œë° ì¶”ì¶œ ì•ˆ ë¨
        if 'ë³´í—˜ë£Œ' in text or 'ë³´ìƒ' in text:
            issues.append("âš ï¸  í‘œ êµ¬ì¡° ì¶”ì¶œ ì‹¤íŒ¨ ê°€ëŠ¥ (í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œë¨)")

    return issues


# ============================================================================
# ë¶„ì„ ì‹¤í–‰
# ============================================================================
def analyze_single_pdf(pdf_info: dict):
    """í•˜ë‚˜ì˜ PDF íŒŒì¼ ë¶„ì„"""
    file_path = pdf_info['file_path']
    filename = pdf_info['filename']

    print(f"\n{'='*100}")
    print(f"ğŸ“„ íŒŒì¼: {filename}")
    print(f"   ë³´í—˜ì‚¬: {pdf_info['insurer']}, ìƒí’ˆ: {pdf_info['product_type']}")
    print(f"   íŒŒì¼ í¬ê¸°: {pdf_info['file_size'] / 1024 / 1024:.2f} MB")
    print(f"{'='*100}")

    # ì¶”ì¶œ
    print("\nğŸ” pdfplumberë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
    start = time.time()
    result = extract_with_pdfplumber(file_path)
    elapsed = time.time() - start

    if not result:
        return None

    text = result['text']
    total_pages = result['total_pages']

    print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {elapsed:.2f}ì´ˆ")
    print(f"   í˜ì´ì§€ ìˆ˜: {total_pages}")
    print(f"   í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text):,}ì")

    # í’ˆì§ˆ ë¶„ì„
    print("\nğŸ“Š í’ˆì§ˆ ë¶„ì„:")
    quality = calculate_text_quality(text)

    print(f"   í•œê¸€ ë¹„ìœ¨: {quality['korean_ratio']:.1%}")
    print(f"   êµ¬ì¡°í™” ì ìˆ˜: {quality['structure_score']:.3f}")
    print(f"   ê°€ë…ì„± ì ìˆ˜: {quality['readability_score']:.3f}")
    print(f"   â­ ì¢…í•© í’ˆì§ˆ: {quality['overall_score']:.3f}")
    print(f"\n   ë°œê²¬ëœ êµ¬ì¡°:")
    print(f"   - ì œNì¥: {quality['chapters']}ê°œ")
    print(f"   - ì œNì¡°: {quality['articles']}ê°œ")

    # UDS í•´ì„ë ¥
    print("\nğŸ¯ UDS í•´ì„ë ¥:")
    uds = calculate_uds_interpretation(text)

    print(f"   ì´í•´ë„ (U): {uds['understanding']:.1f}/100")
    print(f"   ìƒì„¸ë„ (D): {uds['detail']:.1f}/100")
    print(f"   êµ¬ì¡°í™” (S): {uds['structure']:.1f}/100")
    print(f"   â­ UDS ì´ì : {uds['total']:.1f}/100")

    # ë¬¸ì œì  ë¶„ì„
    print("\nâš ï¸  ì ì¬ì  ë¬¸ì œì :")
    issues = analyze_potential_issues(text)

    if issues:
        for issue in issues:
            print(f"   {issue}")
    else:
        print(f"   âœ… íŠ¹ë³„í•œ ë¬¸ì œì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # Upstage ê¶Œì¥ ì—¬ë¶€
    print("\nğŸ’¡ Upstage ë„ì… ê¶Œì¥ë„:")
    recommendation_score = 0

    if quality['overall_score'] < 0.7:
        recommendation_score += 30
        print(f"   [+30ì ] í’ˆì§ˆ ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤ ({quality['overall_score']:.3f})")

    if quality['articles'] < 10:
        recommendation_score += 25
        print(f"   [+25ì ] ì¡°í•­ êµ¬ì¡° ì¸ì‹ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({quality['articles']}ê°œ)")

    if len(issues) >= 2:
        recommendation_score += 25
        print(f"   [+25ì ] ë‹¤ìˆ˜ì˜ ë¬¸ì œì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤ ({len(issues)}ê°œ)")

    if uds['structure'] < 50:
        recommendation_score += 20
        print(f"   [+20ì ] êµ¬ì¡°í™” ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤ ({uds['structure']:.1f})")

    if recommendation_score == 0:
        print(f"   âœ… í˜„ì¬ ì¶”ì¶œ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
    else:
        print(f"\n   â­ Upstage ê¶Œì¥ ì ìˆ˜: {recommendation_score}/100")
        if recommendation_score >= 50:
            print(f"   ğŸ¯ Upstage Document Parse ë„ì…ì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤!")
        elif recommendation_score >= 30:
            print(f"   ğŸ’¡ Upstage Document Parse ë„ì…ì„ ê³ ë ¤í•´ë³¼ ë§Œí•©ë‹ˆë‹¤.")
        else:
            print(f"   â„¹ï¸  UpstageëŠ” ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤.")

    return {
        'filename': filename,
        'pages': total_pages,
        'text_length': len(text),
        'elapsed_time': round(elapsed, 2),
        'quality': quality,
        'uds': uds,
        'issues_count': len(issues),
        'recommendation_score': recommendation_score
    }


def print_summary(all_results):
    """ì „ì²´ ê²°ê³¼ ìš”ì•½"""
    print("\n" + "="*100)
    print("ğŸ“Š ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("="*100)

    # í…Œì´ë¸” í—¤ë”
    print(f"\n{'íŒŒì¼ëª…':45s} | {'í˜ì´ì§€':6s} | {'í…ìŠ¤íŠ¸':10s} | {'í’ˆì§ˆ':6s} | {'UDS':6s} | {'ë¬¸ì œ':4s} | {'ê¶Œì¥':4s}")
    print("-" * 100)

    # ê° íŒŒì¼ ê²°ê³¼
    for r in all_results:
        if r:
            filename_short = r['filename'][:43] + '..' if len(r['filename']) > 45 else r['filename']
            print(
                f"{filename_short:45s} | "
                f"{r['pages']:6d} | "
                f"{r['text_length']:10,d} | "
                f"{r['quality']['overall_score']:6.3f} | "
                f"{r['uds']['total']:6.1f} | "
                f"{r['issues_count']:4d} | "
                f"{r['recommendation_score']:4d}"
            )

    # í‰ê· 
    print("-" * 100)
    valid_results = [r for r in all_results if r]

    if valid_results:
        avg_quality = sum(r['quality']['overall_score'] for r in valid_results) / len(valid_results)
        avg_uds = sum(r['uds']['total'] for r in valid_results) / len(valid_results)
        avg_recommendation = sum(r['recommendation_score'] for r in valid_results) / len(valid_results)

        print(f"{'í‰ê· ':45s} | {'':6s} | {'':10s} | {avg_quality:6.3f} | {avg_uds:6.1f} | {'':4s} | {avg_recommendation:4.0f}")

    print("\n" + "="*100)
    print("ğŸ’¡ Upstage Document Parse ë„ì… í•„ìš”ì„± í‰ê°€")
    print("="*100)

    if valid_results:
        avg_recommendation = sum(r['recommendation_score'] for r in valid_results) / len(valid_results)

        print(f"\ní‰ê·  ê¶Œì¥ ì ìˆ˜: {avg_recommendation:.0f}/100")

        if avg_recommendation >= 50:
            print("\nğŸ¯ ê²°ë¡ : Upstage Document Parse ë„ì…ì„ **ê°•ë ¥íˆ ê¶Œì¥**í•©ë‹ˆë‹¤!")
            print("\nê¸°ëŒ€ íš¨ê³¼:")
            print("  âœ… í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¶”ì¶œ í’ˆì§ˆ 10-30% í–¥ìƒ")
            print("  âœ… ë³´í—˜ì•½ê´€ êµ¬ì¡°(ì œNì¥, ì œNì¡°) ìë™ ì¸ì‹")
            print("  âœ… í‘œ ìë™ ì¶”ì¶œ ë° êµ¬ì¡°í™”")
            print("  âœ… OCR í’ˆì§ˆ ê°œì„  (ì´ë¯¸ì§€ ê¸°ë°˜ PDF)")
            print("  âœ… ìŠ¤ë§ˆíŠ¸ ì²­í‚¹ìœ¼ë¡œ í•™ìŠµ íš¨ìœ¨ í–¥ìƒ")

        elif avg_recommendation >= 30:
            print("\nğŸ’¡ ê²°ë¡ : Upstage Document Parse ë„ì…ì„ **ê³ ë ¤**í•´ë³¼ ë§Œí•©ë‹ˆë‹¤.")
            print("\nê¸°ëŒ€ íš¨ê³¼:")
            print("  âœ… ì¼ë¶€ ë¬¸ì„œì˜ ì¶”ì¶œ í’ˆì§ˆ ê°œì„ ")
            print("  âœ… êµ¬ì¡°í™” ì ìˆ˜ í–¥ìƒ")

        else:
            print("\nâ„¹ï¸  ê²°ë¡ : í˜„ì¬ pdfplumber ì¶”ì¶œ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
            print("   UpstageëŠ” ì„ íƒì‚¬í•­ì´ë©°, í•„ìš” ì‹œ íŠ¹ì • ë¬¸ì„œì—ë§Œ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")


# ============================================================================
# ë©”ì¸
# ============================================================================
def main():
    print("\n" + "="*80)
    print("ğŸ”¬ í˜„ì¬ ì‹œìŠ¤í…œì˜ PDF ì¶”ì¶œ í’ˆì§ˆ ë¶„ì„")
    print("="*80)
    print("\npdfplumber ê¸°ë°˜ í˜„ì¬ ì¶”ì¶œ í’ˆì§ˆì„ ë¶„ì„í•˜ì—¬")
    print("Upstage Document Parse ë„ì…ì˜ í•„ìš”ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.\n")

    # ìƒ˜í”Œ PDF ê°€ì ¸ì˜¤ê¸°
    samples = get_sample_pdfs(limit=5)

    if not samples:
        print("\nâŒ ë¶„ì„í•  PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"í™•ì¸ ê²½ë¡œ:")
        print(f"  - {PDF_DIR}")
        print(f"  - {PDF_DIR_LLM}")
        return

    print(f"âœ… {len(samples)}ê°œ PDF íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")

    # ê° íŒŒì¼ ë¶„ì„
    all_results = []

    for i, pdf_info in enumerate(samples, 1):
        print(f"\n\n{'#'*100}")
        print(f"ë¶„ì„ ì§„í–‰: {i}/{len(samples)}")
        print(f"{'#'*100}")

        result = analyze_single_pdf(pdf_info)
        all_results.append(result)

    # ìš”ì•½ ì¶œë ¥
    print_summary(all_results)

    print("\n" + "="*80)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
