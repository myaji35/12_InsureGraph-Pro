# Story 3.4: Rate Limiting & Monitoring - êµ¬í˜„ ì™„ë£Œ

**Story ID**: 3.4
**Story Name**: Rate Limiting & Monitoring
**Story Points**: 3
**Status**: âœ… Completed
**Epic**: Epic 3 - API & Service Layer

---

## ğŸ“‹ Story ê°œìš”

### ëª©í‘œ
API ë³´í˜¸ ë° ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ Rate Limitingê³¼ Metrics ìˆ˜ì§‘ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
1. **Rate Limiting**: IP/ì‚¬ìš©ì ê¸°ë°˜ ìš”ì²­ ì œí•œ
2. **Request Logging**: ëª¨ë“  ìš”ì²­/ì‘ë‹µ ë¡œê¹…
3. **Performance Metrics**: ì‘ë‹µ ì‹œê°„, ìš”ì²­ ìˆ˜ ë“± ìˆ˜ì§‘
4. **Error Tracking**: ì—ëŸ¬ ì¶”ì  ë° ë¶„ì„
5. **Monitoring Endpoints**: Prometheus metrics, í†µê³„, í—¬ìŠ¤ ì²´í¬

### ë³´í˜¸ ê¸°ëŠ¥
- DDoS ê³µê²© ë°©ì–´
- API ë‚¨ìš© ë°©ì§€
- ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ì‹¤ì‹œê°„ ì—ëŸ¬ ì¶”ì 

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### Middleware Stack

```
Request
  â†“
CORS Middleware
  â†“
GZip Middleware
  â†“
Request Logging Middleware
  â”œâ”€ Generate Request ID
  â”œâ”€ Log request (method, path, IP, user)
  â”œâ”€ Measure response time
  â””â”€ Record metrics
  â†“
Rate Limiting Middleware
  â”œâ”€ Check IP/User rate limit
  â”œâ”€ Increment counter
  â”œâ”€ Add headers (X-RateLimit-*)
  â””â”€ Reject if exceeded (429)
  â†“
Application Logic
  â†“
Response
  â”œâ”€ Add X-Request-ID
  â”œâ”€ Add X-Response-Time
  â””â”€ Add X-RateLimit-* headers
```

### Metrics Flow

```
Request â†’ Logging Middleware
            â†“
          Record:
          - Request count
          - Response time
          - Status code
          - User info
            â†“
        Metrics Store
          - In-Memory (Development)
          - Redis/Prometheus (Production)
            â†“
    Monitoring Endpoints
      /api/v1/monitoring/metrics    (Prometheus format)
      /api/v1/monitoring/stats       (JSON stats)
      /api/v1/monitoring/errors      (Error logs)
      /api/v1/monitoring/health/detailed
```

---

## ğŸ“ êµ¬í˜„ íŒŒì¼

### 1. Rate Limiting (`app/core/rate_limit.py` - 310 lines)

**ì£¼ìš” í´ë˜ìŠ¤**:

```python
class RateLimitStore:
    """
    Rate limit ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” In-Memory ìŠ¤í† ì–´

    Production: Redisë¡œ êµì²´ í•„ìš”
    """
    def get(self, key: str) -> Optional[Dict]
    def set(self, key: str, value: Dict)
    def cleanup_expired(self, window_seconds: int)

class RateLimiter:
    """
    Rate Limiter í´ë˜ìŠ¤

    Sliding window ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
    """
    def __init__(
        self,
        max_requests: int = 100,
        window_seconds: int = 60,
        identifier_func: Optional[Callable] = None
    )

    async def check_rate_limit(self, request: Request) -> tuple[bool, Dict]:
        """
        Rate limit í™•ì¸

        Returns:
            (allowed, info)
            - allowed: bool - ìš”ì²­ í—ˆìš© ì—¬ë¶€
            - info: Dict - rate limit ì •ë³´
        """

class RateLimitMiddleware(BaseHTTPMiddleware):
    """Rate Limiting Middleware"""
    async def dispatch(self, request: Request, call_next):
        # Check rate limit
        allowed, info = await self.rate_limiter.check_rate_limit(request)

        if not allowed:
            raise HTTPException(
                status_code=429,
                detail="Too many requests",
                headers={
                    "X-RateLimit-Limit": str(info["limit"]),
                    "X-RateLimit-Remaining": "0",
                    "Retry-After": str(window_seconds),
                }
            )

        # Add headers to response
        response = await call_next(request)
        response.headers["X-RateLimit-Limit"] = str(info["limit"])
        response.headers["X-RateLimit-Remaining"] = str(info["remaining"])

        return response
```

**ì—”ë“œí¬ì¸íŠ¸ë³„ Rate Limiter**:
```python
# Login endpoint: 5 requests per 5 minutes
login_rate_limiter = RateLimiter(max_requests=5, window_seconds=300)

# Query endpoint: 20 requests per minute
query_rate_limiter = create_user_rate_limiter(max_requests=20, window_seconds=60)

# Document upload: 10 requests per hour
upload_rate_limiter = create_user_rate_limiter(max_requests=10, window_seconds=3600)
```

### 2. Logging & Metrics (`app/core/logging.py` - 450 lines)

**Request Logging Middleware**:
```python
class RequestLoggingMiddleware(BaseHTTPMiddleware):
    """ëª¨ë“  HTTP ìš”ì²­ì„ ë¡œê¹…í•˜ëŠ” ë¯¸ë“¤ì›¨ì–´"""
    async def dispatch(self, request: Request, call_next):
        # Generate request ID
        request_id = str(uuid4())[:8]

        # Record start time
        start_time = time.time()

        # Log request
        logger.info(f"[{request_id}] {method} {path} | IP: {ip}")

        # Process
        response = await call_next(request)

        # Calculate duration
        duration_ms = (time.time() - start_time) * 1000

        # Log response
        logger.info(
            f"[{request_id}] {method} {path} | "
            f"Status: {response.status_code} | "
            f"Duration: {duration_ms:.2f}ms"
        )

        # Add headers
        response.headers["X-Request-ID"] = request_id
        response.headers["X-Response-Time"] = f"{duration_ms:.2f}ms"

        # Record metrics
        _record_request_metrics(method, path, status_code, duration_ms)

        return response
```

**Metrics Store**:
```python
class MetricsStore:
    """ë©”íŠ¸ë¦­ ì €ì¥ì†Œ"""
    def record_request(
        self,
        method: str,
        path: str,
        status_code: int,
        duration_ms: float,
        user_id: str = "anonymous"
    ):
        # Request count
        self.request_count[endpoint] += 1

        # Duration (keep last 1000)
        self.request_duration[endpoint].append(duration_ms)

        # Status codes
        self.status_codes[status_code] += 1

        # User requests
        self.requests_by_user[user_id] += 1

    def get_stats(self) -> Dict:
        """í†µê³„ ì¡°íšŒ"""
        # Calculate percentiles
        p50 = percentile(all_durations, 0.50)
        p95 = percentile(all_durations, 0.95)
        p99 = percentile(all_durations, 0.99)

        return {
            "uptime_seconds": uptime,
            "total_requests": total_requests,
            "total_errors": total_errors,
            "error_rate": error_rate,
            "requests_per_second": rps,
            "response_time": {
                "p50_ms": p50,
                "p95_ms": p95,
                "p99_ms": p99,
            },
            "top_endpoints": top_5_endpoints,
            "status_codes": status_distribution,
        }

    def get_prometheus_metrics(self) -> str:
        """Prometheus í˜•ì‹ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        return """
        # HELP http_requests_total Total HTTP requests
        # TYPE http_requests_total counter
        http_requests_total{method="GET",path="/api/v1/"} 150

        # HELP http_request_duration_milliseconds HTTP request duration
        # TYPE http_request_duration_milliseconds histogram
        http_request_duration_milliseconds{method="GET",path="/api/v1/"} 45.2
        """
```

**Error Tracker**:
```python
class ErrorTracker:
    """ì—ëŸ¬ ì¶”ì  ë° ë¶„ì„"""
    def track_error(
        self,
        error: Exception,
        request: Optional[Request] = None,
        context: Optional[Dict] = None
    ):
        error_info = {
            "timestamp": datetime.now().isoformat(),
            "error_type": type(error).__name__,
            "error_message": str(error),
            "stack_trace": traceback if DEBUG else None,
            "request": {
                "method": request.method,
                "path": request.url.path,
                "client_host": request.client.host,
            },
            "context": context,
        }

        self.errors.append(error_info)
        logger.error(f"Error tracked: {error_type}")

    def get_error_summary(self) -> Dict:
        """ì—ëŸ¬ ìš”ì•½"""
        return {
            "total_errors": len(self.errors),
            "error_types": error_type_counts,
            "recent_errors": last_5_errors,
        }
```

### 3. Monitoring Endpoints (`app/api/v1/endpoints/monitoring.py` - 195 lines)

**GET /api/v1/monitoring/metrics** (Prometheus):
```python
@router.get("/metrics", response_class=Response)
async def get_metrics():
    """Prometheus ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    metrics_store = get_metrics_store()
    prometheus_metrics = metrics_store.get_prometheus_metrics()

    return Response(
        content=prometheus_metrics,
        media_type="text/plain; version=0.0.4"
    )
```

**GET /api/v1/monitoring/stats** (JSON):
```python
@router.get("/stats")
async def get_stats() -> Dict:
    """ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ"""
    stats = metrics_store.get_stats()

    return {
        "timestamp": datetime.now().isoformat(),
        "app_name": "InsureGraph Pro",
        "version": "1.0.0",
        "stats": stats,
    }
```

**GET /api/v1/monitoring/errors**:
```python
@router.get("/errors")
async def get_errors() -> Dict:
    """ì—ëŸ¬ ë¡œê·¸ ì¡°íšŒ"""
    # In production: Admin only
    error_summary = error_tracker.get_error_summary()

    return {
        "timestamp": datetime.now().isoformat(),
        "errors": error_summary,
    }
```

**GET /api/v1/monitoring/health/detailed**:
```python
@router.get("/health/detailed")
async def detailed_health_check() -> Dict:
    """ìƒì„¸ í—¬ìŠ¤ ì²´í¬"""
    # Determine health based on error rate
    if error_rate > 0.5:
        overall_status = "unhealthy"
    elif error_rate > 0.1:
        overall_status = "degraded"
    else:
        overall_status = "healthy"

    return {
        "status": overall_status,
        "components": {
            "database": "ok",
            "cache": "ok",
            "api": "ok",
        },
        "metrics": {
            "uptime_seconds": uptime,
            "total_requests": total,
            "error_rate": error_rate,
            "response_time_p95_ms": p95,
        },
        "errors": error_summary,
    }
```

### 4. Main App Integration (`app/main.py` - updated)

```python
from app.core.rate_limit import RateLimitMiddleware
from app.core.logging import RequestLoggingMiddleware

# Request logging middleware
app.add_middleware(RequestLoggingMiddleware)

# Rate limiting middleware (100 requests per minute)
app.add_middleware(RateLimitMiddleware, max_requests=100, window_seconds=60)
```

### 5. Tests (`tests/test_monitoring.py` - 185 lines)

**í…ŒìŠ¤íŠ¸ êµ¬ì¡°**:
```python
# 1. Monitoring endpoints (4 tests)
class TestMonitoringEndpoints:
    test_get_metrics
    test_get_stats
    test_get_errors
    test_detailed_health_check

# 2. Rate limiting (2 tests)
class TestRateLimiting:
    test_rate_limit_headers
    test_rate_limit_exceeded

# 3. Request logging (2 tests)
class TestRequestLogging:
    test_request_id_header
    test_response_time_header

# 4. Metrics collection (2 tests)
class TestMetricsCollection:
    test_metrics_after_requests
    test_prometheus_format

# 5. Integration (1 test)
class TestMonitoringIntegration:
    test_full_monitoring_flow
```

---

## ğŸ”‘ í•µì‹¬ êµ¬í˜„ ë‚´ìš©

### 1. Rate Limiting ì•Œê³ ë¦¬ì¦˜

**Sliding Window**:
```
Window: 60 seconds
Limit: 100 requests

Time:  0s        30s        60s        90s
       |----------|----------|----------|
Req:   50         30         20         40

At 30s: count=80  (allowed)
At 60s: count=50  (reset window, allowed)
At 90s: count=60  (allowed)
```

**Rate Limit Headers**:
```
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 2025-11-25T21:00:00Z
Retry-After: 60
```

### 2. Request Logging Format

```
[a1b2c3d4] GET /api/v1/query | IP: 192.168.1.1 | User: authenticated
[a1b2c3d4] GET /api/v1/query | Status: 200 | Duration: 125.45ms
```

### 3. Metrics Collection

**Collected Metrics**:
- Request count per endpoint
- Response time (p50, p95, p99)
- Status code distribution
- Error count by type
- Requests per user

**Prometheus Format**:
```
# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="GET",path="/api/v1/query"} 1234

# HELP http_request_duration_milliseconds HTTP request duration
# TYPE http_request_duration_milliseconds histogram
http_request_duration_milliseconds{method="GET",path="/api/v1/query"} 125.45
```

### 4. Error Tracking

**Tracked Information**:
```json
{
  "timestamp": "2025-11-25T20:30:00",
  "error_type": "ValueError",
  "error_message": "Invalid input",
  "stack_trace": "...",  // DEBUG only
  "request": {
    "method": "POST",
    "path": "/api/v1/query",
    "client_host": "192.168.1.1"
  },
  "context": {...}
}
```

---

## ğŸ“Š ì‚¬ìš© ì˜ˆì‹œ

### 1. Rate Limit í™•ì¸

```bash
curl -v http://localhost:8000/api/v1/
```

**ì‘ë‹µ í—¤ë”**:
```
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 99
X-RateLimit-Reset: 2025-11-25T21:00:00Z
X-Request-ID: a1b2c3d4
X-Response-Time: 12.34ms
```

### 2. Prometheus Metrics ì¡°íšŒ

```bash
curl http://localhost:8000/api/v1/monitoring/metrics
```

**ì‘ë‹µ**:
```
# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="GET",path="/api/v1/"} 150

# HELP http_request_duration_milliseconds HTTP request duration
# TYPE http_request_duration_milliseconds histogram
http_request_duration_milliseconds{method="GET",path="/api/v1/"} 45.2
```

### 3. ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ

```bash
curl http://localhost:8000/api/v1/monitoring/stats
```

**ì‘ë‹µ**:
```json
{
  "timestamp": "2025-11-25T20:30:00",
  "app_name": "InsureGraph Pro",
  "version": "1.0.0",
  "stats": {
    "uptime_seconds": 3600,
    "total_requests": 1234,
    "total_errors": 12,
    "error_rate": 0.0097,
    "requests_per_second": 0.34,
    "response_time": {
      "p50_ms": 45.2,
      "p95_ms": 125.8,
      "p99_ms": 250.3
    },
    "top_endpoints": {
      "GET /api/v1/query": 500,
      "POST /api/v1/auth/login": 300,
      "GET /api/v1/documents": 200
    },
    "status_codes": {
      "200": 1100,
      "201": 50,
      "400": 30,
      "401": 20,
      "500": 34
    }
  }
}
```

### 4. ìƒì„¸ í—¬ìŠ¤ ì²´í¬

```bash
curl http://localhost:8000/api/v1/monitoring/health/detailed
```

**ì‘ë‹µ**:
```json
{
  "status": "healthy",
  "timestamp": "2025-11-25T20:30:00",
  "app": {
    "name": "InsureGraph Pro",
    "version": "1.0.0",
    "environment": "production"
  },
  "components": {
    "database": "ok",
    "cache": "ok",
    "api": "ok"
  },
  "metrics": {
    "uptime_seconds": 3600,
    "total_requests": 1234,
    "requests_per_second": 0.34,
    "error_rate": 0.0097,
    "response_time_p95_ms": 125.8
  },
  "errors": {
    "total": 12,
    "types": {
      "ValueError": 8,
      "KeyError": 3,
      "HTTPException": 1
    }
  }
}
```

---

## ğŸ¯ ê²€ì¦ ë° í’ˆì§ˆ ë³´ì¦

### 1. Rate Limiting í…ŒìŠ¤íŠ¸
âœ… **2ê°œ í…ŒìŠ¤íŠ¸ êµ¬í˜„**
- Rate limit í—¤ë” í™•ì¸
- Rate limit ì´ˆê³¼ ì‹œë‚˜ë¦¬ì˜¤

### 2. Logging í…ŒìŠ¤íŠ¸
âœ… **2ê°œ í…ŒìŠ¤íŠ¸ êµ¬í˜„**
- Request ID í—¤ë”
- Response time í—¤ë”

### 3. Metrics í…ŒìŠ¤íŠ¸
âœ… **2ê°œ í…ŒìŠ¤íŠ¸ êµ¬í˜„**
- ìš”ì²­ í›„ ë©”íŠ¸ë¦­ í™•ì¸
- Prometheus í˜•ì‹ ê²€ì¦

### 4. Integration í…ŒìŠ¤íŠ¸
âœ… **1ê°œ í…ŒìŠ¤íŠ¸ êµ¬í˜„**
- ì „ì²´ ëª¨ë‹ˆí„°ë§ í”Œë¡œìš°

---

## ğŸš€ Production ì¤€ë¹„ì‚¬í•­

### í˜„ì¬ êµ¬í˜„ (Development)
- In-Memory storage
- ë‹¨ì¼ ì„œë²„ í™˜ê²½
- ê¸°ë³¸ rate limiting

### Production ê¶Œì¥ì‚¬í•­

**1. Redis ì‚¬ìš©**:
```python
# Rate limit storage
from redis import Redis
redis_client = Redis(host='localhost', port=6379)

class RedisRateLimitStore:
    def get(self, key: str):
        return redis_client.get(key)

    def set(self, key: str, value: Dict, ttl: int):
        redis_client.setex(key, ttl, json.dumps(value))
```

**2. Prometheus Integration**:
```python
from prometheus_client import Counter, Histogram, generate_latest

REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'path', 'status']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'path']
)
```

**3. Grafana Dashboard**:
- Request rate
- Response time (p50, p95, p99)
- Error rate
- Active users
- Top endpoints

**4. Alerting**:
```yaml
# Alert rules
groups:
  - name: api_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_errors_total[5m]) > 0.1
        annotations:
          summary: "High error rate detected"

      - alert: SlowResponses
        expr: http_request_duration_p95 > 1000
        annotations:
          summary: "Slow response times (p95 > 1s)"
```

---

## ğŸ“ ê²°ë¡ 

### êµ¬í˜„ ì™„ë£Œ ì‚¬í•­
âœ… **Rate Limiting** (310 lines)
  - Sliding window algorithm
  - IP/User based limiting
  - Endpoint-specific limits
  - Rate limit headers

âœ… **Request Logging** (450 lines)
  - Request/Response logging
  - Request ID tracking
  - Response time measurement
  - Error tracking

âœ… **Metrics Collection**
  - Request count
  - Response time percentiles
  - Status code distribution
  - Error tracking

âœ… **Monitoring Endpoints** (195 lines)
  - Prometheus metrics
  - JSON stats
  - Error logs
  - Detailed health check

âœ… **Tests** (185 lines, 11 tests)

### Story Points ë‹¬ì„±
- **ì¶”ì •**: 3 points
- **ì‹¤ì œ**: 3 points
- **ìƒíƒœ**: âœ… **COMPLETED**

### Epic 3 ì§„í–‰ ìƒí™©
```
Epic 3: API & Service Layer
â”œâ”€ Story 3.1: Query API Endpoints (5 pts) âœ…
â”œâ”€ Story 3.2: Document Upload API (5 pts) âœ…
â”œâ”€ Story 3.3: Authentication & Authorization (5 pts) âœ…
â”œâ”€ Story 3.4: Rate Limiting & Monitoring (3 pts) âœ…
â””â”€ Story 3.5: API Documentation (3 pts) â³ Next

Progress: 18/21 points (86% complete)
```

### ì£¼ìš” ì„±ê³¼
1. **API ë³´í˜¸**: Rate limitingìœ¼ë¡œ DDoS/ë‚¨ìš© ë°©ì§€
2. **ì™„ì „í•œ ëª¨ë‹ˆí„°ë§**: Request, metrics, errors ì¶”ì 
3. **Prometheus í˜¸í™˜**: Production ëª¨ë‹ˆí„°ë§ ì¤€ë¹„
4. **ì‹¤ì‹œê°„ ê´€ì°°ì„±**: Request ID, response time ì¶”ì 
5. **Production ì¤€ë¹„**: Redis/Prometheus í™•ì¥ ê°€ëŠ¥

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ìƒì„±ëœ íŒŒì¼
1. `app/core/rate_limit.py` (310 lines)
2. `app/core/logging.py` (450 lines)
3. `app/api/v1/endpoints/monitoring.py` (195 lines)
4. `app/api/v1/router.py` (updated)
5. `app/main.py` (updated - middleware)
6. `tests/test_monitoring.py` (185 lines)

### Monitoring ì—”ë“œí¬ì¸íŠ¸
- Metrics: `GET /api/v1/monitoring/metrics`
- Stats: `GET /api/v1/monitoring/stats`
- Errors: `GET /api/v1/monitoring/errors`
- Health: `GET /api/v1/monitoring/health/detailed`

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# ëª¨ë“  ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
pytest tests/test_monitoring.py -v

# Coverage
pytest tests/test_monitoring.py --cov=app.core --cov=app.api.v1.endpoints.monitoring
```

---

**ì‘ì„±ì¼**: 2025-11-25
**ì‘ì„±ì**: Claude (AI Assistant)
**Epic**: Epic 3 - API & Service Layer
**Status**: âœ… Completed - Story 3.4 Done! ğŸ‰
