"""
Citation Validator

ë‹µë³€ì˜ ê·¼ê±°(Citation) ê²€ì¦ ë° ì¶œì²˜ ì¶”ì 
"""

from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

from loguru import logger


class CitationValidator:
    """
    Citation ê²€ì¦ í´ë˜ìŠ¤

    ë‹µë³€ì— í¬í•¨ëœ ì¸ìš©(Citation)ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ê³ ,
    í• ë£¨ì‹œë„¤ì´ì…˜ì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """

    @staticmethod
    def validate_citation(citation: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """
        ë‹¨ì¼ Citationì„ ê²€ì¦í•©ë‹ˆë‹¤.

        Args:
            citation: Citation ë°ì´í„°
                {
                    "document_id": "...",
                    "article_num": "ì œ1ì¡°",
                    "title": "ìš©ì–´ì˜ ì •ì˜",
                    "page": 5,
                    "text": "...",
                    "confidence": 0.92
                }

        Returns:
            Tuple[bool, Optional[str]]: (ìœ íš¨ ì—¬ë¶€, ì—ëŸ¬ ë©”ì‹œì§€)
        """
        required_fields = ["document_id", "text"]

        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        for field in required_fields:
            if field not in citation or not citation[field]:
                return False, f"Missing required field: {field}"

        # Confidence í™•ì¸ (ìˆëŠ” ê²½ìš°)
        if "confidence" in citation:
            confidence = citation["confidence"]
            if not isinstance(confidence, (int, float)) or not (0 <= confidence <= 1):
                return False, f"Invalid confidence score: {confidence}"

            # Confidenceê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ê²½ê³ 
            if confidence < 0.7:
                logger.warning(
                    f"Low confidence citation: {confidence} for document {citation['document_id']}"
                )

        # Text ê¸¸ì´ í™•ì¸ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ê²½ìš° ì˜ì‹¬)
        text = citation["text"]
        if len(text) < 10:
            return False, "Citation text too short (< 10 characters)"
        if len(text) > 5000:
            return False, "Citation text too long (> 5000 characters)"

        return True, None

    @staticmethod
    def validate_citations(citations: List[Dict[str, Any]]) -> Tuple[bool, List[str]]:
        """
        ì—¬ëŸ¬ Citationsë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.

        Args:
            citations: Citation ë¦¬ìŠ¤íŠ¸

        Returns:
            Tuple[bool, List[str]]: (ëª¨ë‘ ìœ íš¨ ì—¬ë¶€, ì—ëŸ¬ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸)
        """
        if not citations:
            return False, ["No citations provided"]

        errors = []

        for idx, citation in enumerate(citations):
            valid, error = CitationValidator.validate_citation(citation)
            if not valid:
                errors.append(f"Citation {idx + 1}: {error}")

        all_valid = len(errors) == 0
        return all_valid, errors

    @staticmethod
    def check_citation_coverage(
        answer: str,
        citations: List[Dict[str, Any]],
        min_citations: int = 1
    ) -> Tuple[bool, Optional[str]]:
        """
        ë‹µë³€ì´ ì¶©ë¶„í•œ ê·¼ê±°(Citation)ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

        Args:
            answer: ë‹µë³€ í…ìŠ¤íŠ¸
            citations: Citation ë¦¬ìŠ¤íŠ¸
            min_citations: ìµœì†Œ í•„ìš”í•œ Citation ê°œìˆ˜

        Returns:
            Tuple[bool, Optional[str]]: (ì¶©ë¶„ ì—¬ë¶€, ê²½ê³  ë©”ì‹œì§€)
        """
        if len(citations) < min_citations:
            return False, f"Insufficient citations: {len(citations)} < {min_citations}"

        # ë‹µë³€ ê¸¸ì´ ëŒ€ë¹„ Citation ë¹„ìœ¨ í™•ì¸
        answer_length = len(answer)
        if answer_length > 500 and len(citations) < 2:
            return False, "Long answer requires multiple citations (>= 2)"

        if answer_length > 1000 and len(citations) < 3:
            return False, "Very long answer requires multiple citations (>= 3)"

        return True, None

    @staticmethod
    def extract_source_reference(citation: Dict[str, Any]) -> str:
        """
        Citationì—ì„œ ì¶œì²˜ ì°¸ì¡° ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            citation: Citation ë°ì´í„°

        Returns:
            str: ì¶œì²˜ ì°¸ì¡° (ì˜ˆ: "ì•½ê´€ ì œ1ì¡° ì œ3í•­ (5í˜ì´ì§€)")
        """
        parts = []

        # ì¡°í•­ ë²ˆí˜¸
        if "article_num" in citation and citation["article_num"]:
            parts.append(f"{citation['article_num']}")

        # ì¡°í•­ ì œëª©
        if "title" in citation and citation["title"]:
            parts.append(f"({citation['title']})")

        # í˜ì´ì§€
        if "page" in citation and citation["page"]:
            parts.append(f"{citation['page']}í˜ì´ì§€")

        # Document ID (ê°„ëµí™”)
        if "document_id" in citation:
            doc_id_short = str(citation["document_id"])[:8]
            parts.append(f"[ë¬¸ì„œ: {doc_id_short}...]")

        reference = " ".join(parts) if parts else "ì¶œì²˜ ì •ë³´ ì—†ìŒ"
        return reference

    @staticmethod
    def format_citations_for_display(citations: List[Dict[str, Any]]) -> str:
        """
        Citationsë¥¼ ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•  í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            citations: Citation ë¦¬ìŠ¤íŠ¸

        Returns:
            str: í¬ë§·ëœ ì¶œì²˜ ë¬¸ìì—´
        """
        if not citations:
            return "ê·¼ê±° ìë£Œ ì—†ìŒ"

        formatted_lines = ["## ğŸ“š ê·¼ê±° ìë£Œ"]
        formatted_lines.append("")

        for idx, citation in enumerate(citations, 1):
            reference = CitationValidator.extract_source_reference(citation)
            formatted_lines.append(f"{idx}. {reference}")

            # Confidence score (ìˆëŠ” ê²½ìš°)
            if "confidence" in citation:
                confidence_pct = int(citation["confidence"] * 100)
                formatted_lines.append(f"   - ì‹ ë¢°ë„: {confidence_pct}%")

        return "\n".join(formatted_lines)

    @staticmethod
    def append_citation_footer(answer: str, citations: List[Dict[str, Any]]) -> str:
        """
        ë‹µë³€ì— Citation footerë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

        Args:
            answer: ì›ë³¸ ë‹µë³€
            citations: Citation ë¦¬ìŠ¤íŠ¸

        Returns:
            str: Citation footerê°€ ì¶”ê°€ëœ ë‹µë³€
        """
        if not citations:
            # Citationì´ ì—†ëŠ” ê²½ìš° ê²½ê³  ì¶”ê°€
            footer = "\n\n---\nâš ï¸ **ì£¼ì˜**: ì´ ë‹µë³€ì€ ì•½ê´€ ê·¼ê±°ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ì‹¤ì œ ì•½ê´€ì„ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            return answer + footer

        # Citation footer ì¶”ê°€
        citations_display = CitationValidator.format_citations_for_display(citations)
        footer = f"\n\n---\n{citations_display}\n\n**â„¹ï¸ ì•ˆë‚´**: ìœ„ ë‹µë³€ì€ ì‹¤ì œ ì•½ê´€ ì¡°í•­ì— ê·¼ê±°í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ í•´ë‹¹ ì•½ê´€ì„ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."

        return answer + footer

    @staticmethod
    def check_hallucination_risk(
        answer: str,
        citations: List[Dict[str, Any]],
        confidence_threshold: float = 0.7
    ) -> Tuple[str, List[str]]:
        """
        í• ë£¨ì‹œë„¤ì´ì…˜ ìœ„í—˜ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.

        Args:
            answer: ë‹µë³€ í…ìŠ¤íŠ¸
            citations: Citation ë¦¬ìŠ¤íŠ¸
            confidence_threshold: Confidence ì„ê³„ê°’

        Returns:
            Tuple[str, List[str]]: (ìœ„í—˜ë„ ë ˆë²¨, ê²½ê³  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸)
                ìœ„í—˜ë„: "low", "medium", "high"
        """
        warnings = []
        risk_score = 0

        # 1. Citation ê°œìˆ˜ í™•ì¸
        if len(citations) == 0:
            risk_score += 40
            warnings.append("ë‹µë³€ì— ê·¼ê±° ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤")
        elif len(citations) == 1 and len(answer) > 300:
            risk_score += 20
            warnings.append("ê¸´ ë‹µë³€ì— ë¹„í•´ ê·¼ê±° ìë£Œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")

        # 2. Confidence score í™•ì¸
        if citations:
            low_confidence_count = sum(
                1 for c in citations
                if "confidence" in c and c["confidence"] < confidence_threshold
            )
            if low_confidence_count > 0:
                risk_score += 15 * low_confidence_count
                warnings.append(f"{low_confidence_count}ê°œì˜ ê·¼ê±° ìë£Œê°€ ë‚®ì€ ì‹ ë¢°ë„ë¥¼ ë³´ì…ë‹ˆë‹¤")

        # 3. ë‹µë³€ ë‚´ ìˆ˜ì¹˜ í™•ì¸ (ê¸ˆì•¡, ë‚ ì§œ ë“±)
        import re
        numbers = re.findall(r'\d{1,3}(?:,\d{3})*(?:\.\d+)?', answer)
        if len(numbers) > 3 and len(citations) < 2:
            risk_score += 15
            warnings.append("êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ê°€ ë§ì§€ë§Œ ê·¼ê±° ìë£Œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")

        # 4. ë‹¨ì •ì  í‘œí˜„ í™•ì¸
        definitive_keywords = ["ë°˜ë“œì‹œ", "ì ˆëŒ€", "100%", "ì „ì•¡", "ë¬´ì¡°ê±´"]
        definitive_count = sum(1 for keyword in definitive_keywords if keyword in answer)
        if definitive_count > 0:
            risk_score += 10
            warnings.append("ë‹¨ì •ì  í‘œí˜„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤ - ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # ìœ„í—˜ë„ íŒì •
        if risk_score >= 50:
            risk_level = "high"
        elif risk_score >= 25:
            risk_level = "medium"
        else:
            risk_level = "low"

        return risk_level, warnings

    @staticmethod
    def create_traceability_report(
        query: str,
        answer: str,
        citations: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ì¶”ì  ê°€ëŠ¥ì„± ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            query: ì‚¬ìš©ì ì§ˆì˜
            answer: ë‹µë³€
            citations: Citation ë¦¬ìŠ¤íŠ¸
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

        Returns:
            Dict[str, Any]: ì¶”ì  ê°€ëŠ¥ì„± ë³´ê³ ì„œ
        """
        # Citation ê²€ì¦
        citations_valid, citation_errors = CitationValidator.validate_citations(citations)
        coverage_ok, coverage_warning = CitationValidator.check_citation_coverage(answer, citations)
        risk_level, risk_warnings = CitationValidator.check_hallucination_risk(answer, citations)

        report = {
            "timestamp": datetime.utcnow().isoformat(),
            "query": query,
            "answer_length": len(answer),
            "citations_count": len(citations),
            "validation": {
                "citations_valid": citations_valid,
                "citation_errors": citation_errors,
                "coverage_ok": coverage_ok,
                "coverage_warning": coverage_warning,
            },
            "risk_assessment": {
                "level": risk_level,
                "warnings": risk_warnings,
            },
            "citations": [
                {
                    "reference": CitationValidator.extract_source_reference(c),
                    "confidence": c.get("confidence", 0.0),
                    "document_id": c.get("document_id"),
                    "article": c.get("article_num"),
                }
                for c in citations
            ],
            "compliance_status": "pass" if (citations_valid and coverage_ok and risk_level != "high") else "fail",
            "metadata": metadata or {},
        }

        return report
